{
    "contents" : "#implement SVM with SMO method as a S3 calss\n#(only linear kernel for now)\n#\n#algorithm follows the paper: \n#  Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines\n#  by John C. Platt\n\n#Author:Chyi-Kwei Yau\n#date: 2012.03.07\n\nsource(\"SVM_func.R\")\n\nSVM<-function(x, y, C, max.iter=3000, tolerance=1e-3){\n  #x is the input matrix\n  #y is the response (+1 or -1)\n  m<-dim(x)[1]\n  n<-dim(x)[2]\n  \n  #error check\n  #if(m != length(y)){\n  #  print(\"input and response have different length\")\n  #  return;\n  #}\n  \n  model.attr<-list(); #build class\n  class(model.attr) <- \"SVM\" #set class name\n  # set attribute\n  model.attr$x<-x\n  model.attr$y<-y\n  model.attr$C<-C\n  model.attr$m<-m\n  model.attr$n<-dim(x)[2]\n  model.attr$max.iter<-max.iter\n  model.attr$tolerance<-tolerance\n  model.attrkernel<-kernel\n  \n  # initialize parameter\n  model.attr$alpha<-rep(0, m)\n  #model.attr$errorCache<-rep(0,m)\n  model.w<-rep(0,n)\n  model.attr$b<-0\n  \n  #training\n  iter=0\n  numChanged=0\n  examAll=T; #go through all data first\n  \n  start.time<-proc.time()\n  \n  while( numChanged >0 || examAll){\n    \n    numChanged=0\n    non.zero.alpha<-which( (model.attr$alpha!=0) &  (model.attr$alpha!=model.attr$C) )\n    \n    cat(\"iter=\", iter, \", support vector number=\",length(non.zero.alpha),\"\\n\", sep=\"\")\n    \n    if(examAll || length(non.zero.alpha)==0 ){    \n      cat(\"  --exam all in this iteration\\n\")\n      update.cand<-seq(1,model.attr$m)\n    }\n    else{\n      cat(\"  --exam \", length(non.zero.alpha),  \" alphas in this iteration\\n\",sep=\"\")\n      update.cand<-non.zero.alpha\n    }\n    \n    #train Full first\n    for( index in update.cand){\n    #for( index in 1:1){\n      err<-getErr(model.attr, index)\n      #cat(err,\"=err\\n\")\n      \n      label<-model.attr$y[index]\n      \n      # if err is grater than tolerance and not at bound\n      if( ((err*label) < (-1)*model.attr$tolerance && (model.attr$alpha[index] < model.attr$C) \n      ) || ((err*label) > model.attr$tolerance && (model.attr$alpha[index] >0) )){\n        \n        #select 2nd index \n        #TODO: repace by selectIndex later\n        index2<-selectIndex(index, err, model.attr)\n        #index2<-randSelectIndex(index, model.attr$m)\n        #cat(length(index2),\" = index2\\n\")\n        \n        label2<-model.attr$y[index2]        \n        err2<-getErr(model.attr, index2)\n        #cat(err2,\"= err2\\n\")\n        \n        s<-(label * label2)\n        C<-model.attr$C\n      \n        #old alpha\n        alpha<-model.attr$alpha[index]\n        alpha2<-model.attr$alpha[index2]\n        \n        #upper & lower bound for new aplha2\n        if(label != label2){\n          high = min(C, C + alpha2 - alpha )\n          low = max(0 , alpha2 - alpha)\n        }else{\n          #label == label2\n          high = min(C, alpha2 + alpha )\n          low = max(0 , alpha2 + alpha - C)  \n        }\n        \n        #make sure low != high\n        if(low == high){\n          #cat(\"high = low, go to next alpha\\n\")\n          next\n        }\n        \n        #get eta\n        x<-model.attr$x[index,]\n        x2<-model.attr$x[index2,]\n        #use linear kernel for now\n        #TODO: replace by kernel function..\n        eta = sum(x*x) + sum(x2*x2) - 2*sum(x*x2)\n        \n        if(eta<=0){\n          #cat(\"eat <=0\\n\")\n          next\n        }\n        \n        #update alpha2\n        new.alpha2 <- (alpha2 + (label2*(err-err2)/eta))\n        #cat(\"new.alpha2=\",new.alpha2, \" high=\",high, \" low=\",low,\"\\n\")\n        new.alpha2 <- getAlpha(new.alpha2, high, low)\n        \n        #check update value\n        if( abs(new.alpha2 - alpha2) < 1e-5){\n          #alpha2 change too small\n          #cat(\"  --alpha change too small\\n\")\n          next\n        }\n        \n        model.attr$alpha[index2]<-new.alpha2\n        \n        #update err in index2\n        #model.attr$errorCache[index2]<-getErr(model.attr, index2)\n      \n        \n        #update alpha\n        new.alpha<- alpha + s*(alpha2 - new.alpha2)\n        model.attr$alpha[index]<-new.alpha\n        \n        #update err in index\n        #model.attr$errorCache[index]<-getErr(model.attr, index)\n        \n        #calculate b1, formula (20)\n        b1 =  err + (label*(new.alpha - alpha)*sum(x*x))+(label2*(new.alpha2-alpha2)*sum(x*x2)) + model.attr$b\n        \n        #calculate b2, formula (21)\n        b2 = err2 + (label*(new.alpha - alpha)*sum(x*x2))+(label2*(new.alpha2-alpha2)*sum(x2*x2)) + model.attr$b\n        \n        #update b\n        model.attr$b <- update.b(b1, b2, new.alpha, new.alpha2, model.attr$C)\n        #cat(\"b1=\",b1, \"b2=\", b2, \"b=\", model.attr$b,\"\\n\")\n        \n        #alpha change number \n        numChanged<-numChanged+1\n      }\n    }#end for i\n    \n    \n    #check next iter run full or not\n    if(examAll == T){\n      examAll=F\n    }\n    else if(numChanged==0){\n      cat(\"  --no alpha changed in this iteration. Exam all in next iteration\\n\")\n      examAll=T\n    }\n    cat(\"  --num alpha changed=\",numChanged,\"\\n\",sep=\"\")\n    iter=iter+1\n    cat(\"\\n\")\n    \n    #force break\n    if(iter > max.iter){\n      cat(\"Warning: SVM not converge but reach max iterations!\",\"\\n\")\n      break\n    }\n    \n  }#end while\n  \n  #calculate w\n  model.attr$w<-getW(model.attr)\n  \n  #end time\n  end.time<-proc.time()\n  running.time<-end.time - start.time\n  cat(\"\\n\")\n  cat(\"SVM training finished. Elapsed time=\", running.time[\"elapsed\"], \" secs\")\n  \n  return(model.attr)\n}\n\n",
    "created" : 1349570824208.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "734341926",
    "id" : "999BB104",
    "lastKnownWriteTime" : 1349746317,
    "path" : "~/GitHub/MachineLearning/SVM/SVM/SVM.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : true,
    "type" : "r_source"
}